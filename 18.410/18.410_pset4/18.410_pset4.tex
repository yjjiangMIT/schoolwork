\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{color}
\usepackage{forest}
\usepackage{fancyhdr}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\title{6.046/18.410 Problem Set 4}
\author{Yijun Jiang\vspace{3pt}\\Collaborator: Hengyun Zhou, Eric Lau}
%\email{yjjiang@mit.edu}
\date{\today}

\pagestyle{fancy}
\lhead{Yijun Jiang}
\rhead{6.046/18.410 Problem Set 4}

\begin{document}
\maketitle
\section{Learn to Fuel Wisely}
\subsection{Part (a)}
\noindent\textbf{Description}:

First run APSP on the graph $G=(V,E)$ with edge weights $l(u,v)$ (since no negative weighted edges exist, we can use $|V|$ times Dijkstra). Construct a new unweighted and undirected graph $G'=(V,E')$, using all original vertices but newly defined edges, as follows:

Check $\delta(u,v)$ for all pairs. If $\delta(u,v)\leqslant K$, create an edge $(u,v)$. By this construction, all the island pairs that can be reached within one fill are connected.

Run APSP on the new graph $G'$ (since it is unweighted, we can use $|V|$ times BFS). Then pick out the longest one among all-pair shortest paths in $G'$. This gives the value $t$ we want.

The pseudocode is shown below.
\begin{algorithm}
\caption{Finding the smallest refilling time that guarantees travelling between any vertex pair}
\begin{algorithmic}[1]
\Procedure{FuelWisely}{$G$}
\State{$\delta=\textsc{APSP-VTimesDijkstra}(G)$}
\State{Create a new unweighted and undirected graph $G'=(V,E')$, where $E'=\varnothing$}
\For{$u$ in $V$}
	\For{$v$ in $V$}
		\If{$u\neq v$ \textbf{and} $\delta(u,v)\leqslant K$}
			\State{Add edge $(u,v)$ to $E'$}
		\EndIf
	\EndFor
\EndFor
\State{$\delta'=\textsc{APSP-VTimesBFS}(G')$}
\State{A double \textbf{for} loop to find $t=\max(\delta'(u,v))$}
\State{\Return{$t$}}
\EndProcedure
\end{algorithmic}
\end{algorithm}

~

\noindent\textbf{Correctness}:

We prove that in order to get from any vertex $u$ to any distinct vertex $v$ in the original graph $G$, the smallest number of refills, denoted here by $t_{uv}$, equals the length of the shortest path, $\delta'(u,v)$, in $G'$. Then $t=\displaystyle{\max_{u,v}}(t_{uv})=\displaystyle{\max_{u,v}}(\delta'(u,v))$ is the smallest number of refills that guarantees travelling between any vertex pair.

Given a shortest path $p'_{uv}$ from $u$ to $v$ in $G'$, we can use the following refilling strategy: start by filling at $u$, then until reaching $v$, we always go to the subsequent vertex in $p'_{uv}$ and refill there. This can always be done since, by the construction of $G'$, we can reach from a vertex in $p'_{uv}$ to its subsequent vertex in one fill. This strategy thus involves $\delta'(u,v)$ refills. Since $t_{uv}$ is the smallest number of refills from $u$ to $v$, $t_{uv}\leqslant\delta'(u,v)$.

On the other hand, if a refilling strategy involves filling at $u$ and refilling at some (or maybe no) intermediate vertices, then going from one (re)filling vertex to the next requires only one fill. If this strategy involves $t_{uv}$ refills, then there is a path in $G'$ connecting $u$ and $v$ with length $t_{uv}$. It cannot be shorter than the shortest path from $u$ to $v$ in $G'$. So $t_{uv}\geqslant\delta'(u,v)$.

In conclusion, $t_{uv}=\delta'(u,v)$. Then the correctness of this algorithm follows.

~

\noindent\textbf{Runtime}:

The first APSP on $G$ by $|V|$ times Dijkstra costs $V\times O(E+V\log V)=O(VE+V^2\log V)$ time.

The construction of $G'$ is of $O(V^2)$ time because all the vertex pairs need to be checked.

The second APSP by BFS costs $V\times O(E'+V)=O(VE'+V^2)$ time, where $E'$ is the set of newly defined edges. In the worst case, $G'$ is dense and this time becomes $O(V^3)$.

Finally, finding the maximum among all $\delta'(u,v)$ is of $O(V^2)$ time.

In all, this algorithm runs in $O(V^3)=O(N^3)$ time.

\subsection{Part (b)}
\noindent\textbf{Description}:

First calculate the shortest path between this new island $L$ (denoted by $s_L$ as a vertex) and other previously existing islands (denoted by $u,v,\cdots$ as vertices). %Assign $\delta(s_L,s_L)=0$ and $\delta(s_L,u)=\infty$ for all previously existing vertices $u$. Then for all $u$ directly connected to $s_L$ and all $v$, use $w(s_L,u)+\delta(u,v)$ to relax $\delta(s_L,v)$. Since the graph is undirected, we also get $\delta(v,s_L)$ for all $v$.
This can be done by running Dijkstra's algorithm since no negative weighted edges exist.

Then update the shortest path between the previously existing islands. For each vertex pair $u,v$, relax $\delta(u,v)$ by $\delta(u,s_L)+\delta(s_L,v)$.

The pseudocode is shown below.
\begin{algorithm}
\caption{Updating APSP after adding another vertex}
\begin{algorithmic}[1]
\Procedure{UpdateASAP}{$G,s_L$}%,A_{s2G}$}
%\State{\Comment{Assume $G=(V,E)$ is the old graph}}
%\State{\Comment{Assume $A_{s2G}$ stores all $u\in V$ that are connected to $s_L$, as well as $w(s_L,u)$}}
%\State{$\delta(s_L,s_L)\gets0$}
%\For{$u$ in $V$}
%	\State{$\delta(s_L,u)\gets\infty$}
%\EndFor
\State{Run Dijkstra to find $\delta(s_L,u)=\delta(u,s_L)$ for all $u\in V$}
%\For{$u$ in $A_{s2G}$}
%	\For{$v$ in $V$}
%		\If{$w(s_L,u)+\delta(u,v)<\delta(s_L,v)$}
%			\State{$\delta(s_L,v)\gets w(s_L,u)+\delta(u,v)$, $\delta(v,s_L)\gets\delta(s_L,v)$}
%		\EndIf
%	\EndFor
%\EndFor
\For{$u$ in $V$}
	\For{$v$ in $V$}
		\If{$\delta(u,s_L)+\delta(s_L,v)<\delta(u,v)$}
			\State{$\delta(u,v)\gets\delta(u,s_L)+\delta(s_L,v)$}
		\EndIf
	\EndFor
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

~

\noindent\textbf{Correctness}:

(1) [Calculation of $\delta(s_L,v)$] 
%The shortest path from $s_L$ to a previously existing vertex $v$ can only visit $s_L$ once, otherwise there will be a cycle and the path becomes longer (unless it is a zero weight cycle, then $s_L$ can be but does not need to be visited multiple times; for practical reasons, fuel consumption should be positive anyway). Thus, this path first contains $(s_L,u)$ for some vertex $u\in V$ and then stays inside the old graph $G=(V,E)$: $p_{s_L,v}=\{(s_L,u)\}\cup p^G_{u,v}$. Therefore, when relaxing $\delta(s_L,v)$ by some $u$ directly connected to $s_L$, we can use $\delta(u,v)$ of the old graph. Since we loop over all such $u$ for relaxation, for each $v\in V$, the optimal $u$ is selected such that $w(s_L,u)+\delta(u,v)$ is minimized. Then this must be the shortest path from $s_L$ to $v$.
The correctness is guaranteed by the validity of Dijkstra's algorithm.

(2) [Calculation of $\delta(u,v)$] The only possibility to reduce $\delta(u,v)$ is to use $s_L$ as an intermediate vertex. Therefore, by trying to relax $\delta(u,v)$ using $\delta(u,s_L)+\delta(s_L,v)$ (both are calculated previously), we can decide whether using $s_L$ as an intermediate vertex shortens the path. Then we are guaranteed to get the shortest paths between all previously existing vertex pairs.

~

\noindent\textbf{Runtime}:

Dijkstra takes $O(E+V\log V)$. $\delta(u,v)$ require doubly nested loops, which costs $O(V^2)$. Thus the total runtime is $O(V^2)=O(N^2)$.

\section{Lazy Random Homework Solving}
\subsection{Part (a)}
\noindent\textbf{Proof}:

By induction on $k$. When $k=1$, suppose that there are $r_1$ friends working on this problem. $r_1\geqslant r$. The assignment becomes invalid when all these $r_1$ friends are assigned to TA Nirvan or TA Kelly. The possibility is $P[1,\textup{invalid}]=2\times2^{-r_1}\leqslant 2^{1-r}=k2^{1-r}$. So the statement is true for the base case.

When $k>1$, suppose the statement holds for $k-1$. Therefore, $P[k-1,\textup{invalid}]\leqslant(1-k)2^{1-r}$. In other words, $P[k-1,\textup{valid}]\geqslant 1-(k-1)2^{1-r}$. When we add the $k$-th problem, we have
\begin{equation*}
	P[k,\textup{valid}]=P[k-1,\textup{valid}]P[1,\textup{valid}|\textup{assignment valid for previous $k-1$ problems}]
\end{equation*}
where the second factor is a conditional probability: the probability for the assignment to be valid for the one-problem case (the $k$-th problem), under the condition that the assignment is valid for the $k-1$-problem case (the privious $k-1$ problems). If we use the unconditional probability, the equality becomes an inequality because the unconditional probability is always no larger.
\begin{equation*}
	P[k,\textup{valid}]\geqslant P[k-1,\textup{valid}]P[1,\textup{valid}]
\end{equation*}
The inequality can be further relaxed,
\begin{align*}
	P[k,\textup{valid}]&\geqslant(1-(k-1)2^{1-r})(1-2^{1-r})\\
	&=1-k2^{1-r}+(k-1)2^{2-2r}\\
	&\geqslant1-k2^{1-r}
\end{align*}
which means $P[k,\textup{invalid}]\leqslant k2^{1-r}$. Therefore, by induction, the statements is true for all $k$. Larry fails to choose a valid assignment with probability at most $k2^{1-r}$.

There is, however, a much simpler way to interprete this result. I will write it in the following part.

\subsection{Part (b)}
We need $k2^{1-r}<1$, which means $k<2^{r-1}$. This guarantees that valid assignments exist. 
%However, this bound can be relaxed, since the inequality $P[k,\textup{invalid}]\leqslant k2^{1-r}$ derived in the previous part is quite loose. I feel that the tightest (highest) bound is $k<\binom{2r-1}{r}$. I cannot prove this. However, I can show that if $k\geqslant\binom{2r-1}{r}$, there is a choice of Larry's friends (who does which problem) that makes it impossible for a valid assignment to exist. \textcolor{red}{TODO}

In order to intuitively justify its correctness, we first think of how one problem might make an assignment invalid. This happens when all friends working on it are assigned to the same TA. For $k$ problems, there are at most $2k\times 2^{n-r}$ such invalid assignments, where the factor $2$ comes from two TAs and the factor $2^{n-r}$ assigns all irrevalant friends (at most $n-r$ of them) to TAs. Since there are in total $2^n$ assignments, we must make sure that $2k\times 2^{n-r}<2^n$, which means $k<2^{r-1}$.


\subsection{Part (c)}
Suppose $k\leqslant 2^{r-2}$, then $P[k,\textup{invalid}]\leqslant k2^{1-r}\leqslant\frac{1}{2}$. The chance for a random assignment to be valid is more than a half. We can thus use the following Las Vegas algorithm:

~

\noindent\textbf{Description}:

We use two arrays of length $k$, $T\!A_0$ and $T\!A_1$, to store if Larry can get feedback from either TA on each problem. For example, if he gets feedback on problem $i$ from TA Nirvan but not from TA Kelly, then $T\!A_0[i]=1$ and $T\!A_1[i]=0$. We use two integers $count_0$ and $count_1$ to store the sum of all elements in $T\!A_0$ and $T\!A_1$, respectively. If eventually $count_0=count_1=k$, then the assignment is valid. Also, we use an array of length $n$, called $A$, to record the assignment.

We begin a loop by randomly assign friends to TAs. This is done by generating a random bit for each friend, with equal probability being $0$ or $1$. Store this bit in the corresponding entry of $A$. If a friend is assigned $0$, then check his/her done problems in $T\!A_0$. If the corresponding entry is $0$, set it to $1$ and update $count_0$ by adding $1$. If a friend is assigned $1$, then do the same thing to $T\!A_1$ and $count_1$.

When all friends are processed, if $count_0=count_1=k$, the assignment is valid and we jump out of the loop. Output $A$ as the assignment. Otherwise, the assignment is not valid. Go the the start of the loop and try another random assignment.

The pesudocode is shown below.
\begin{algorithm}
\caption{Finding valid assignment}
\begin{algorithmic}[1]
\Procedure{ValidAssignment}{$F,n,k$}
\State{\Comment{Assume $F$ is an array of length $n$ that stores the problems done by each friend in $F[i].problems$}}
\While{\textbf{true}}
	\State{Initialize $T\!A_0$ and $T\!A_1$ to length-$k$ arrays of $0$}
	\State{Initialize $A$ to length-$n$ array of $0$}
	\State{$count_0\gets0$, $count_1\gets0$}
	\For{$i=0:n-1$}
		\State{$A[i]\gets\textsc{RandBit}()$}
		\If{$A[i]=0$}
			\For{$p$ in $F[i].problems$}
				\If{$T\!A_0[p]=0$}
					\State{$T\!A_0[p]\gets1$}
					\State{$count_0\gets count_0+1$}
				\EndIf
			\EndFor
		\Else{}
			\For{$p$ in $F[i].problems$}
				\If{$T\!A_1[p]=0$}
					\State{$T\!A_1[p]\gets1$}
					\State{$count_1\gets count_1+1$}
				\EndIf
			\EndFor
		\EndIf
	\EndFor
	\If{$count_0=k$ \textbf{and} $count_1=k$}
		\State{\textbf{break}}
	\EndIf
\EndWhile
\State{\Return{$A$}}
\EndProcedure
\end{algorithmic}
\end{algorithm}

~

\noindent\textbf{Correctness}:

Unless a valid assignment is obtained, the procedure will not break the while loop. Therefore, if it terminates, it must give the correct output. If $k\leqslant 2^{r-2}$, then the expectation of number of while loops is no larger than $2$. So the algorithm is expected to terminate in finite time.

~

\noindent\textbf{Runtime}:

In each while loop, every friend is assigned a random bit, which costs $O(n)$. Moreover, for each friend, all the problems that he/she does are visited. The total number of problems being considered is $O(kn)$, since $O(n)$ friends are doing each of the $k$ problems (although $r$ may be far less than $n$, $O(n)$ is a safe bound for ``no less than $r$"). So altogether, the for loop in the main while loop costs $O(kn)$. The rest part of the while loop costs constant time. The while loop is expected to be executed twice. Therefore, the overall expected runtime is $O(kn)$, which is linear in terms of the input size, which is also $O(kn)$.

\subsection{Part (d)}
\noindent\textbf{Description}:

Randomly find a friend $f$ and let him/her try all the shoes. By doing this we find the correct shoe $s$ for $f$, and we can also partition all the shoes around $s$. Then for every other friend, let him/her try $s$. By doing this we partition them around $f$. Then we have a subset of shoes smaller than $s$ and a subset of friends whose feet are smaller than $f$, as well as a subset of shoes larger than $s$ and a subset of friends whose feet are larger than $f$. We recurse on both the smaller subset and the larger subset.

The pseudocode is shown below.
\begin{algorithm}
\caption{Matching shoes with friends}
\begin{algorithmic}[1]
\Procedure{QuickShoeMatching}{$F,S$}
\If{$F.length=1$}
	\State{$F[0].shoe=S[0]$}
\Else{}
	\State{Randomly pick pivot $i$ in $0,1,\cdots,F.length-1$}
	\State{Partition $S$ by $F[i].size$: $S=[S_1,s,S_2]$, where $s.size=F[i].size$}
	\State{Partition $F$ by $s.size$: $F=[F_1,F[i],F_2]$}
	\State{\Comment{It is guaranteed that $S_1.length=F_1.length$ and $S_2.length=F_2.length$}}
	\State{\Call{QuickShoeMatching}{$F_1,S_1$}}
	\State{\Call{QuickShoeMatching}{$F_2,S_2$}}
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

~

\noindent\textbf{Correctness}:

Say friend $f$ has shoe $s$. By partitioning the shoes around $f$, all the shoes smaller than $s$ are picked out as $S_1$. By partitioning the friends around $s$, all the friends whose feet are smaller than $f$ are picked out as $F_1$. Shoes smaller than $s$ must belong to friends whose feet are smaller than $f$. The same is true on the larger side. Therefore, matches are constrained within either the smaller side or the larger side. So recursively calling \textsc{QuickShoeMatching} finds all the matches.

~

\noindent\textbf{Runtime}:

Say partition of $F$ and $S$ happens at the rank-$k$ element, where $k$ is uniformly distributed. Then
\begin{equation*}
T(n)=T(k-1)+T(n-k)+O(n)
\end{equation*}

This is the same recursion as \textsc{Quicksort}. Therefore, the expected runtime of \textsc{QuickShoeMatching} is $O(n\log n)$.

\end{document}
